{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS_YP0rLMLgC",
        "outputId": "50e5144f-e838-4006-c13e-0e7013d1d0e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq -U wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSXi4rQ-W4mU",
        "outputId": "b408c78e-279b-4574-93ab-97a78ad52461"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Log in to your W&B account\n",
        "import wandb\n",
        "from google.colab import userdata\n",
        "wandb.login(key = userdata.get('WANDB_API_KEY'), verify = True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbrY3lHzQ5mP"
      },
      "source": [
        "\n",
        "### Instructions\n",
        "\n",
        "https://wandb.ai/miteshk/assignments/reports/Assignment-1--VmlldzozNjk4NDE\n",
        "\n",
        "The goal of this assignment is twofold: (i) implement and use gradient descent (and its variants) with\n",
        "backpropagation for a classification task (ii) get familiar with wandb which is a cool tool for running and keeping track of a large number of experiments\n",
        "We strongly recommend that you work on this assignment in a team of size 2. Both the members\n",
        "of the team are expected to work together (in a subsequent viva both members will be expected to answer questions, explain the code, etc).\n",
        "Collaborations and discussions with other groups are strictly prohibited.\n",
        "You must use Python (numpy and pandas) for your implementation.\n",
        "You cannot use the following packages from keras, pytorch, tensorflow: optimizers, layers\n",
        "If you are using any packages from keras, pytorch, tensorflow then post on moodle first to check with the instructor.\n",
        "You can run the code in a jupyter notebook on colab by enabling GPUs.\n",
        "You have to generate the report in the same format as shown below using wandb.ai. You can start by cloning this report using the clone option above. Most of the plots that we have asked for below can be (automatically) generated using the apis provided by wandb.ai. You will upload a link to this report on gradescope.\n",
        "You also need to provide a link to your github code as shown below. Follow good software engineering practices and set up a github repo for the project on Day 1. Please do not write all code on your local machine and push everything to github on the last day. The commits in github should reflect how the code has evolved during the course of the assignment.\n",
        "You have to check moodle regularly for updates regarding the assignment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0VNl9ZyMbSI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNbFZuEgMcVE"
      },
      "source": [
        "###Problem Statement\n",
        "In this assignment you need to implement a feedforward neural network and write the backpropagation code for training the network. We strongly recommend using numpy for all matrix/vector operations. You are not allowed to use any automatic differentiation packages. This network will be trained and\n",
        "tested using the Fashion-MNIST dataset. Specifically, given an input image (28 x 28 = 784\n",
        "pixels) from the Fashion-MNIST dataset, the network will be trained to classify the image\n",
        "into 1 of 10 classes.\n",
        "\n",
        "###Question 1 (2 Marks)\n",
        "Download the fashion-MNIST dataset and plot 1 sample image for each class as shown in the grid below. Use \"from keras.datasets import fashion_mnist\" for getting the fashion mnist dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eumLJyY_MbbZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-07 07:21:07.535878: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-03-07 07:21:07.581103: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-07 07:21:07.581145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-07 07:21:07.583594: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-07 07:21:07.593250: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-03-07 07:21:07.597521: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-07 07:21:08.888173: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "partially initialized module 'keras.src' has no attribute 'utils' (most likely due to a circular import)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fashion_mnist\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/__internal__/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/__internal__/backend/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/src/__init__.py:21\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/src/applications/__init__.py:41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EfficientNetV2M\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EfficientNetV2S\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minception_resnet_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InceptionResNetV2\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minception_v3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InceptionV3\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmobilenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MobileNet\n",
            "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/src/applications/inception_resnet_v2.py:324\u001b[0m\n\u001b[1;32m    320\u001b[0m         x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mActivation(activation, name\u001b[38;5;241m=\u001b[39mac_name)(x)\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;129m@keras\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241m.\u001b[39mregister_keras_serializable()\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomScaleLayer\u001b[39;00m(keras_layers\u001b[38;5;241m.\u001b[39mLayer):\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, scale, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'keras.src' has no attribute 'utils' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erdWqAMpMh5x",
        "outputId": "194de1ec-d08c-4951-fff4-cfcb235d8fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "C3S__TI6Ssmb",
        "outputId": "304bfa33-0bf1-42bb-dcf6-a7f245959376"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ankle boot'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]\n",
        "\n",
        "fmnist_labels = {\n",
        "0 :\t'T-shirt/top',\n",
        "1 :\t'Trouser',\n",
        "2 :\t'Pullover',\n",
        "3 :\t'Dress',\n",
        "4 :\t'Coat',\n",
        "5 :\t'Sandal',\n",
        "6 :\t'Shirt',\n",
        "7 :\t'Sneaker',\n",
        "8 :\t'Bag',\n",
        "9 :\t'Ankle boot'}\n",
        "fmnist_labels[y_train[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVQohUdQTFRS"
      },
      "source": [
        "|Label |\tDescription|\n",
        "|--- |\t---- |\n",
        "|0 |\tT-shirt/top|\n",
        "|1 |\tTrouser|\n",
        "|2 |\tPullover|\n",
        "|3 |\tDress|\n",
        "|4 |\tCoat|\n",
        "|5 |\tSandal|\n",
        "|6 |\tShirt|\n",
        "|7 |\tSneaker|\n",
        "|8 |\tBag|\n",
        "|9 |\tAnkle boot|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "nc_d-kaEcaU-",
        "outputId": "c8d14cdd-2703-44e0-ab9c-a1f98afa2bf7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240219_034547-zb0so09w</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ns24z066/pytorch-demo/runs/zb0so09w' target=\"_blank\">thriving-kumquat-2</a></strong> to <a href='https://wandb.ai/ns24z066/pytorch-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ns24z066/pytorch-demo' target=\"_blank\">https://wandb.ai/ns24z066/pytorch-demo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ns24z066/pytorch-demo/runs/zb0so09w' target=\"_blank\">https://wandb.ai/ns24z066/pytorch-demo/runs/zb0so09w</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "      # Set the project where this run will be logged\n",
        "      project=\"pytorch-demo\"\n",
        "      )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhSTHV3mfkJM"
      },
      "outputs": [],
      "source": [
        "examples = []\n",
        "for i in range(100):\n",
        "    pixels = x_train[i]\n",
        "    image = wandb.Image(pixels, caption=f\"{fmnist_labels[y_train[i]]} {i}\")\n",
        "    examples.append(image)\n",
        "run.log({\"examples\": examples})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSepIRZkBiRJ"
      },
      "source": [
        "Data cleaning for training it to the neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZN_lQ4AW3Wh",
        "outputId": "daf99896-bce2-4b5a-dd0e-82218cd9f32a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "len(np.unique(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3tzOf9TB6E7",
        "outputId": "abca78c0-ee4b-4401-9f09-5c1f1746e809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "one_hot_label [[0 0 0 ... 0 0 1]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "y_train [9 0 0 ... 3 0 5]\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "one_hot_label = np.zeros([y_train.shape[0], len(np.unique(y_train))], dtype=int)\n",
        "for index, item in enumerate(y_train):\n",
        "  one_hot_label[index, item] = 1\n",
        "print('one_hot_label', one_hot_label)\n",
        "print('y_train', y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJdTa8OpMioE"
      },
      "source": [
        "###Question 2 (10 Marks)\n",
        "Implement a feedforward neural network which takes images from the fashion-mnist data as input and outputs a probability distribution over the 10 classes.\n",
        "Your code should be flexible so that it is easy to change the number of hidden layers and the number of neurons in each hidden layer.\n",
        "We will check the code for implementation and ease of use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6Yj2nrNb883",
        "outputId": "a3f1c264-7bce-43e0-d801-0d6cd6888b02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.80261302])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.rand(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIu2yOQJMjJX"
      },
      "outputs": [],
      "source": [
        "input ---> MNIST Image ----> Hidden Layers --> output ----> Softmax Prob Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2yZWEEelhIaP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_dim, output_dim ,network_layers_architecture: list):\n",
        "\n",
        "        self.main_model = []\n",
        "        for index, layer in enumerate(network_layers_architecture):\n",
        "            self.main_model.append({'weights': [], 'biases': [], 'activation': ''})\n",
        "            if index == 0:\n",
        "                self.main_model[index]['weights'] = np.random.rand(layer['num_neurons'], input_dim)\n",
        "            elif index == len(network_layers_architecture) - 1:\n",
        "                self.main_model[index]['weights'] = np.random.rand(output_dim, layer['num_neurons'])\n",
        "            else:\n",
        "                self.main_model[index]['weights'] = np.random.rand(layer['num_neurons'], layer[index-1]['num_neurons'])\n",
        "            # self.main_model[index]['activation'] =  layer['activation']\n",
        "            self.main_model[index]['biases'] = np.random.rand(1)[0]\n",
        "\n",
        "    def feed_forward(self, input_data):\n",
        "        print(self.main_model[0]['weights'].shape)\n",
        "        final_output = np.dot(self.main_model[0]['weights'], input_data) + self.main_model[0]['biases']\n",
        "        for layer in self.main_model[1:]:\n",
        "            final_output = np.dot(layer['weights'], final_output) + layer['biases']\n",
        "        return final_output\n",
        "\n",
        "    def train(self):\n",
        "        pass\n",
        "\n",
        "    def predict(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLsQ2XB4hJ0X",
        "outputId": "c2b14be5-966e-4752-c1d7-f8c31d452282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 2)\n",
            "[3.85876007 4.21436893 2.98569969 2.7165816  2.11141742]\n"
          ]
        }
      ],
      "source": [
        "nn = NeuralNetwork(2, 5, [{'num_neurons': 3, 'activation': 'relu'}, {'num_neurons': 3, 'activation': 'relu'}])\n",
        "\n",
        "print(nn.feed_forward([1, 2]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3Is9QI8RVVK"
      },
      "source": [
        "\n",
        "\n",
        "###Question 3 (18 Marks)\n",
        "Implement the backpropagation algorithm with support for the following optimisation functions\n",
        "sgd\n",
        "momentum based gradient descent\n",
        "nesterov accelerated gradient descent\n",
        "rmsprop\n",
        "adam\n",
        "nadam\n",
        "(12 marks for the backpropagation framework and 2 marks for each of the optimisation algorithms above)\n",
        "We will check the code for implementation and ease of use (e.g., how easy it is to add a new optimisation algorithm such as Eve). Note that the code should be flexible enough to work with different batch sizes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtcH52IjRgJS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2Omn5LDRhjX"
      },
      "source": [
        "###Question 4 (10 Marks)\n",
        "Use the sweep functionality provided by wandb to find the best values for the hyperparameters listed below. Use the standard train/test split of fashion_mnist (use (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()).  Keep 10% of the training data aside as validation data for this hyperparameter search. Here are some suggestions for different values to try for hyperparameters. As you can quickly see that this leads to an exponential number of combinations. You will have to think about strategies to do this hyperparameter search efficiently. Check out the options provided by wandb.sweep and write down what strategy you chose and why.\n",
        "number of epochs: 5, 10\n",
        "number of hidden layers:  3, 4, 5\n",
        "size of every hidden layer:  32, 64, 128\n",
        "weight decay (L2 regularisation): 0, 0.0005,  0.5\n",
        "learning rate: 1e-3, 1 e-4\n",
        "optimizer:  sgd, momentum, nesterov, rmsprop, adam, nadam\n",
        "batch size: 16, 32, 64\n",
        "weight initialisation: random, Xavier\n",
        "activation functions: sigmoid, tanh, ReLU\n",
        "wandb will automatically generate the following plots. Paste these plots below using the \"Add Panel to Report\" feature. Make sure you use meaningful names for each sweep (e.g. hl_3_bs_16_ac_tanh to indicate that there were 3 hidden layers, batch size was 16 and activation function was ReLU) instead of using the default names (whole-sweep, kind-sweep) given by wandb.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhm0g7NORjVn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUyKA6MpRkBm"
      },
      "source": [
        "\n",
        "###Question 5 (5 marks)\n",
        "We would like to see the best accuracy on the validation set across all the models that you train.\n",
        "wandb automatically generates this plot which summarises the test accuracy of all the models that you tested. Please paste this plot below using the \"Add Panel to Report\" feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIyX2bFzRlWU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KskqOFcRl4E"
      },
      "source": [
        "\n",
        "###Question 6 (20 Marks)\n",
        "Based on the different experiments that you have run we want you to make some inferences about which configurations worked and which did not.\n",
        "Here again, wandb automatically generates a \"Parallel co-ordinates plot\" and a \"correlation summary\" as shown below. Learn about a \"Parallel co-ordinates plot\" and how to read it.\n",
        "By looking at the plots that you get, write down some interesting observations (simple bullet points but should be insightful). You can also refer to the plot in Question 5 while writing these insights. For example, in the above sample plot there are many configurations which give less than 65% accuracy. I would like to zoom into those and see what is happening.\n",
        "I would also like to see a recommendation for what configuration to use to get close to 95% accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bp1m_CPvRnTP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XQJds6JRn21"
      },
      "source": [
        "\n",
        "###Question 7 (10 Marks)\n",
        "For the best model identified above, report the accuracy on the test set of fashion_mnist and plot the confusion matrix as shown below. More marks for creativity (less marks for producing the plot shown below as it is)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyi5lTwPRpH4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV7kKvuHRqIu"
      },
      "source": [
        "\n",
        "###Question 8 (5 Marks)\n",
        "In all the models above you would have used cross entropy loss. Now compare the cross entropy loss with the squared error loss. I would again like to see some automatically generated plots or your own plots to convince me whether one is better than the other.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BpI_B45RrWT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNSlL38qRr0V"
      },
      "source": [
        "\n",
        "###Question 9 (10 Marks)\n",
        "Paste a link to your github code for this assignment\n",
        "Example: \\hrefhttps://github.com/<user-id>/cs6910_assignment1https://github.com/<user-id>/cs6910_assignment1;\n",
        "We will check for coding style, clarity in using functions and a README file with clear instructions on training and evaluating the model (the 10 marks will be based on this)\n",
        "We will also run a plagiarism check to ensure that the code is not copied (0 marks in the assignment if we find that the code is plagiarised)\n",
        "We will check the number of commits made by the two team members and then give marks accordingly. For example, if we see 70% of the commits were made by one team member then that member will get more marks in the assignment (\\textbfnote that this contribution will decide the marks split for the entire assignment and not just this question).\n",
        "We will also check if the training and test data has been split properly and randomly. You will get 0 marks on the assignment if we find any cheating (e.g., adding test data to training data) to get higher accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of3bdvNzRtGS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbHNbn2DRtkz"
      },
      "source": [
        "\n",
        "###Question 10 (10 Marks)\n",
        "Based on your learnings above, give me 3 recommendations for what would work for the MNIST dataset (not Fashion-MNIST). Just to be clear, I am asking you to take your learnings based on extensive experimentation with one dataset and see if these learnings help on another dataset. If I give you a budget of running only 3 hyperparameter configurations as opposed to the large number of experiments you have run above then which 3 would you use and why. Report the accuracies that you obtain using these 3 configurations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk2XHnOwRt3N"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
